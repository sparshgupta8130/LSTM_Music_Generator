{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from collections import defaultdict\n",
    "from torch.autograd import Variable\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "from time import gmtime, strftime\n",
    "from random import shuffle\n",
    "#gc.set_debug(gc.DEBUG_STATS)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_input():\n",
    "    if os.path.exists('data/input_shuffled.txt'):\n",
    "            os.remove('data/input_shuffled.txt')\n",
    "    f = open('data/input_shuffled.txt','w+')\n",
    "    data_=[]\n",
    "    data = ''\n",
    "    for l in open('data/input.txt'):\n",
    "        if '<start>' in l:\n",
    "            data+='<start>\\n'\n",
    "        elif '<end>' in l:\n",
    "            data+='<end>\\n'\n",
    "            data_.append(data)\n",
    "            data = ''\n",
    "        else:\n",
    "            data+=l\n",
    "        #data.append('\\n')\n",
    "    shuffle(data_)\n",
    "    data_shuffled=''\n",
    "    for l in data_:\n",
    "        data_shuffled += l\n",
    "    # print(data_shuffled[:1000])\n",
    "    f.write(data_shuffled)\n",
    "    f.close()\n",
    "\n",
    "file_path = \"./observations/\"\n",
    "directory = os.path.dirname(file_path)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "file_path = \"./saved_models/\"\n",
    "directory = os.path.dirname(file_path)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "data = []\n",
    "j = 0\n",
    "k = 0\n",
    "shuffle_input()\n",
    "for l in open('data/input_shuffled.txt'):\n",
    "    if '<start>' in l:\n",
    "        data.append('$')\n",
    "        j += 1\n",
    "    elif '<end>' in l:\n",
    "        data.append('%')\n",
    "        k += 1\n",
    "    else:\n",
    "        for c in range(len(l)):\n",
    "            data.append(l[c])\n",
    "    #data.append('\\n')\n",
    "print(j)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use original data to create the dictionary\n",
    "data_org = []\n",
    "j = 0\n",
    "k = 0\n",
    "shuffle_input()\n",
    "for l in open('data/input.txt'):\n",
    "    if '<start>' in l:\n",
    "        data_org.append('$')\n",
    "        j += 1\n",
    "    elif '<end>' in l:\n",
    "        data_org.append('%')\n",
    "        k += 1\n",
    "    else:\n",
    "        for c in range(len(l)):\n",
    "            data_org.append(l[c])\n",
    "    #data.append('\\n')\n",
    "\n",
    "\n",
    "unique_char = defaultdict(int)\n",
    "j_ = 0\n",
    "k_ = 0\n",
    "for d in data_org:\n",
    "    if d == '$':\n",
    "        j_ += 1\n",
    "    elif d == '%':\n",
    "        k_ += 1\n",
    "    unique_char[d] += 1\n",
    "#print(len(unique_char))\n",
    "i = 0\n",
    "char_idx = defaultdict(int)\n",
    "for k in unique_char:\n",
    "    char_idx[k] = i\n",
    "    i += 1\n",
    "    \n",
    "idx_char = defaultdict(str)\n",
    "for k in char_idx:\n",
    "    idx_char[char_idx[k]]=k\n",
    "#print(idx_char)\n",
    "\n",
    "dat = np.arange(len(char_idx))\n",
    "len(char_idx)\n",
    "#char_idx\n",
    "#print(j_,k_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(char_idx,data):\n",
    "    output = []\n",
    "    for i in range(len(data)):\n",
    "        aux = np.zeros(len(char_idx))\n",
    "        aux[char_idx[data[i]]] = 1\n",
    "        output.append(aux.copy())\n",
    "    return output\n",
    "\n",
    "def softmaxT(data,T=1):\n",
    "    temp = torch.exp(data/T)\n",
    "    aux = torch.sum(temp)\n",
    "    return temp/aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_data = one_hot_encoder(char_idx,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "output_data = []\n",
    "for i in range(len(oh_data)-1):\n",
    "    input_data.append(oh_data[i].copy())\n",
    "    output_data.append(oh_data[i+1].copy())\n",
    "print(len(input_data))\n",
    "print(len(output_data))\n",
    "#print(input_data[0],output_data[0])\n",
    "#print(input_data[1],output_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n",
    "X_train = input_data[:int(split_ratio*len(input_data))]\n",
    "Y_train_aux = output_data[:int(split_ratio*len(input_data))]\n",
    "X_valid = input_data[int(split_ratio*len(input_data)):]\n",
    "Y_valid_aux = output_data[int(split_ratio*len(input_data)):]\n",
    "Y_train = []\n",
    "Y_valid = []\n",
    "for i in range(len(Y_train_aux)):\n",
    "    Y_train.append(np.argmax(Y_train_aux[i]))\n",
    "for i in range(len(Y_valid_aux)):\n",
    "    Y_valid.append(np.argmax(Y_valid_aux[i]))\n",
    "print(len(X_train),len(Y_train))\n",
    "print(len(X_valid),len(Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMMusic(torch.nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim,num_layers,batch_size=1):\n",
    "        super(LSTMMusic,self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = torch.nn.LSTM(self.input_dim,self.hidden_dim,self.num_layers)\n",
    "        self.fc = torch.nn.Linear(self.hidden_dim,self.output_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "#         return (Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_dim)),\n",
    "#                Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_dim)))\n",
    "        return (Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_dim).cuda()),\n",
    "               Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_dim).cuda()))\n",
    "    \n",
    "    def del_hidden(self):\n",
    "        del self.hidden\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def forward(self,sequence):\n",
    "        out, _ = self.lstm(sequence.view(len(sequence),self.batch_size,-1),self.hidden)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def hidden_st(self,sequence):\n",
    "        return self.lstm(sequence.view(len(sequence),self.batch_size,-1),self.hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUMusic(torch.nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim,num_layers,batch_size=1):\n",
    "        super(LSTMMusic,self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.gru = torch.nn.GRU(self.input_dim,self.hidden_dim,self.num_layers)\n",
    "        self.fc = torch.nn.Linear(self.hidden_dim,self.output_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "#         return (Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_dim)))\n",
    "        return (Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_dim).cuda()))\n",
    "    \n",
    "    def del_hidden(self):\n",
    "        del self.hidden\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def forward(self,sequence):\n",
    "        out, _ = self.gru(sequence.view(len(sequence),self.batch_size,-1),self.hidden)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def hidden_st(self,sequence):\n",
    "        return self.gru(sequence.view(len(sequence),self.batch_size,-1),self.hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(char_idx)\n",
    "OUTPUT_DIM = len(char_idx)\n",
    "HIDDEN_DIM = 100\n",
    "BATCH_SIZE = 1\n",
    "NUM_LAYERS = 1\n",
    "char_size = 25\n",
    "epochs = 5\n",
    "\n",
    "model = LSTMMusic(INPUT_DIM,HIDDEN_DIM,OUTPUT_DIM,NUM_LAYERS,BATCH_SIZE)\n",
    "model.cuda()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "eps = []\n",
    "tr_loss = []\n",
    "va_loss = []\n",
    "tr_acc = []\n",
    "va_acc = []\n",
    "model.hidden = model.init_hidden()\n",
    "ts = strftime(\"100neur_1hid_%Y-%m-%d__%Hh%Mm%Ss_\", gmtime())\n",
    "for epoch in range(epochs):\n",
    "    tot_loss = 0\n",
    "    val_loss = 0\n",
    "    min_val_loss = 999999999999999\n",
    "    iteration = 0\n",
    "    i = 0\n",
    "    l = open('./observations/lstm_music_trial_'+str(ts)+'.txt','a+')\n",
    "    while i < len(X_train):\n",
    "        inputs = X_train[i:min(i+char_size,len(X_train))]\n",
    "        outputs = Y_train[i:min(i+char_size,len(X_train))]\n",
    "        optimizer.zero_grad()\n",
    "        ip = Variable(torch.from_numpy(np.array(inputs)).float().cuda())\n",
    "        del inputs\n",
    "        op = torch.from_numpy(np.array(outputs))\n",
    "        op = Variable(op.type(torch.LongTensor).cuda())\n",
    "        del outputs\n",
    "        out = model(ip)\n",
    "        out = out.view(out.data.shape[0],out.data.shape[2])\n",
    "        loss = loss_fn(out,op)\n",
    "        del ip, op, out\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tot_loss += float(loss.cpu().data.numpy())\n",
    "        if i%(int(len(X_train)/100)) == 0:\n",
    "            print('--',i,loss.data[0])\n",
    "        i += char_size\n",
    "    \n",
    "    #Calculate Validation Loss\n",
    "    i=0\n",
    "    while i < len(X_valid):\n",
    "        inputs = X_valid[i:min(i+char_size,len(X_valid))]\n",
    "        outputs = Y_valid[i:min(i+char_size,len(X_valid))]\n",
    "        optimizer.zero_grad()\n",
    "        ip = Variable(torch.from_numpy(np.array(inputs)).float().cuda())\n",
    "        del inputs\n",
    "        op = torch.from_numpy(np.array(outputs))\n",
    "        op = Variable(op.type(torch.LongTensor).cuda())\n",
    "        del outputs\n",
    "        out = model(ip)\n",
    "        out = out.view(out.data.shape[0],out.data.shape[2])\n",
    "        loss = loss_fn(out,op)\n",
    "        del ip, op, out\n",
    "        val_loss += float(loss.cpu().data.numpy())\n",
    "#         if i%(int(len(X_valid)/100)) == 0:\n",
    "#             print('--',i,loss.data[0])\n",
    "        i += char_size\n",
    "        \n",
    "    #Calculate Training Error\n",
    "    i = 0\n",
    "    correct = 0\n",
    "    #total = 0\n",
    "    while i < len(X_train):\n",
    "        inputs = X_train[i:min(i+char_size,len(X_train))]\n",
    "        outputs = Y_train[i:min(i+char_size,len(X_train))]\n",
    "        optimizer.zero_grad()\n",
    "        ip = Variable(torch.from_numpy(np.array(inputs)).float().cuda())\n",
    "        del inputs\n",
    "        op = torch.from_numpy(np.array(outputs))\n",
    "        op = Variable(op.type(torch.LongTensor).cuda())\n",
    "        del outputs\n",
    "        out = model(ip)\n",
    "        out = out.view(out.data.shape[0],out.data.shape[2])\n",
    "        #print(out.data.shape)\n",
    "        _, predicted = torch.max(out.data,1)\n",
    "        #_, target = torch.max(op.data,1)\n",
    "        correct += (predicted == op.data).sum()\n",
    "        \n",
    "#         if i%(int(len(X_train)/100)) == 0:\n",
    "#             print('--',i,loss.data[0])\n",
    "        i += char_size\n",
    "    tr_acc.append(100*correct/len(X_train))\n",
    "    \n",
    "    #Calculate Validation Error\n",
    "    i = 0\n",
    "    correct = 0\n",
    "    #total = 0\n",
    "    while i < len(X_valid):\n",
    "        inputs = X_valid[i:min(i+char_size,len(X_valid))]\n",
    "        outputs = Y_valid[i:min(i+char_size,len(X_valid))]\n",
    "        optimizer.zero_grad()\n",
    "        ip = Variable(torch.from_numpy(np.array(inputs)).float().cuda())\n",
    "        del inputs\n",
    "        op = torch.from_numpy(np.array(outputs))\n",
    "        op = Variable(op.type(torch.LongTensor).cuda())\n",
    "        del outputs\n",
    "        out = model(ip)\n",
    "        out = out.view(out.data.shape[0],out.data.shape[2])\n",
    "        _, predicted = torch.max(out.data,1)\n",
    "        #_, target = torch.max(op.data,1)\n",
    "        correct += (predicted == op.data).sum()\n",
    "        \n",
    "#         if i%(int(len(X_valid)/100)) == 0:\n",
    "#             print('--',i,loss.data[0])\n",
    "        i += char_size\n",
    "    va_acc.append(100*correct/len(X_valid))\n",
    "        \n",
    "    #model.del_hidden()\n",
    "    print(epoch,'Train Loss : ',tot_loss/len(X_train),'Val Loss : ',val_loss/len(X_valid),\n",
    "          'Train Acc : ',tr_acc[-1],'Val Acc : ',va_acc[-1])\n",
    "    eps.append(epoch)\n",
    "    tr_loss.append(tot_loss/len(X_train))\n",
    "    va_loss.append(val_loss/len(X_valid))\n",
    "    l.write(str(epoch)+' T '+str(tot_loss/len(X_train))+' V '+str(val_loss/len(X_valid))+\n",
    "            'TA'+str(tr_acc[-1])+'VA'+str(va_acc[-1])+'\\n')\n",
    "    l.close()\n",
    "    if val_loss/len(X_valid) <= min_val_loss:\n",
    "        min_val_loss = val_loss/len(X_valid)\n",
    "        iteration = epoch\n",
    "        if os.path.exists('saved_models/model' + str(ts) + '.pt'):\n",
    "            os.remove('saved_models/model' + str(ts) + '.pt')\n",
    "        torch.save(model,'saved_models/model' + str(ts) + '.pt')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(eps,tr_loss)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.plot(eps,va_loss)\n",
    "plt.legend(['Train Loss','Valid Loss'])\n",
    "plt.show()\n",
    "fig.savefig('observations/LossPlot_' + str(ts), dpi=fig.dpi)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(eps,tr_acc)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.plot(eps,va_acc)\n",
    "plt.legend(['Train Accuracy','Valid Accuracy'],loc='lower right')\n",
    "plt.show()\n",
    "fig.savefig('observations/AccPlot_' + str(ts), dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_model = torch.load('saved_models/model' + str(ts) + '.pt')\n",
    "# fin_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '$'\n",
    "T = 0.7\n",
    "pref_oh = one_hot_encoder(char_idx,prefix)\n",
    "\n",
    "ip = Variable(torch.from_numpy(np.array(pref_oh)).float().cuda())\n",
    "out = fin_model(ip)\n",
    "final_out = out[-1,:,:]\n",
    "dist = softmaxT(final_out.data,T).cpu().numpy()\n",
    "dist = dist.reshape(dist.shape[1])\n",
    "seq_len = 800\n",
    "output = []\n",
    "prev_char = np.random.choice(dat,p=dist)\n",
    "output.append(prev_char)\n",
    "for i in range(seq_len):\n",
    "    x = prev_char\n",
    "    #print(dist)\n",
    "    #output.append(x)\n",
    "    ip = np.zeros((1,len(char_idx)))\n",
    "    ip[0,x]=1\n",
    "    #ip = Variable(torch.from_numpy(np.array(ip)).float())\n",
    "    ip = Variable(torch.from_numpy(np.array(ip)).float().cuda())\n",
    "    out = fin_model(ip)\n",
    "    aux = softmaxT(out[-1,:,:].data,T).cpu().numpy()\n",
    "    aux = aux.reshape(aux.shape[1])\n",
    "    prev_char = np.random.choice(dat,p=aux)\n",
    "    output.append(prev_char)\n",
    "\n",
    "output_seq = []\n",
    "for i in range(len(output)):\n",
    "    output_seq.append(idx_char[output[i]])\n",
    "#print(output_seq)\n",
    "l = open('./observations/generated_music_'+str(ts)+'.txt','a+')\n",
    "gen_text = ''\n",
    "for i in output_seq:\n",
    "    if i == '\\n':\n",
    "        l.write(gen_text)\n",
    "        print(gen_text)\n",
    "        gen_text = ''\n",
    "#     elif i == '$':\n",
    "#         gen_text = gen_text + '<start>\\n'\n",
    "#     elif i == '%':\n",
    "#         gen_text = gen_text + '<end>\\n'\n",
    "    else:\n",
    "        gen_text = gen_text + str(i)\n",
    "l.write(gen_text)\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_seq = []\n",
    "seq_char = []\n",
    "while True:\n",
    "    test_seq.append(oh_data[i])\n",
    "    seq_char.append(data[i])\n",
    "    if data[i] == '%':\n",
    "        break\n",
    "    i += 1\n",
    "#len(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = []\n",
    "size = int(len(test_seq))-(len(test_seq)%100)\n",
    "\n",
    "for i in range(len(test_seq)):\n",
    "    ip = Variable(torch.from_numpy(test_seq[i]).float().cuda()).view(1,-1)\n",
    "    #print(ip.data.shape)\n",
    "    out,_ = fin_model.hidden_st(ip)\n",
    "    out = out.view(out.data.shape[2])\n",
    "    #print(out.data.shape)\n",
    "    activations.append(out.data.cpu().numpy())\n",
    "activations = np.array(activations)\n",
    "activations = activations[:size,:]\n",
    "seq = np.reshape(np.array(seq_char[:size]),(20,-1))\n",
    "print(activations.shape)\n",
    "print(seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = np.reshape(activations[:,0],(20,-1))\n",
    "neuron.shape\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(neuron)\n",
    "#plt.colorbar()\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "#plt.colorbar(fig,cax=ax)\n",
    "\n",
    "xaxis = np.arange(0,neuron.shape[1])\n",
    "yaxis = np.arange(0,neuron.shape[0])\n",
    "x,y = np.meshgrid(xaxis,yaxis)\n",
    "#print(x,y)\n",
    "for x_val, y_val in zip(x.flatten(),y.flatten()):\n",
    "    ax.text(x_val,y_val,seq[y_val,x_val],va='center',ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
