{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from collections import defaultdict\n",
    "from torch.autograd import Variable\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "from time import gmtime, strftime\n",
    "from random import shuffle\n",
    "import pickle\n",
    "#gc.set_debug(gc.DEBUG_STATS)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_input():\n",
    "    if os.path.exists('data/input_shuffled.txt'):\n",
    "            os.remove('data/input_shuffled.txt')\n",
    "    f = open('data/input_shuffled.txt','w+')\n",
    "    data_=[]\n",
    "    data = ''\n",
    "    for l in open('data/input.txt'):\n",
    "        if '<start>' in l:\n",
    "            data+='<start>\\n'\n",
    "        elif '<end>' in l:\n",
    "            data+='<end>\\n'\n",
    "            data_.append(data)\n",
    "            data = ''\n",
    "        else:\n",
    "            data+=l\n",
    "        #data.append('\\n')\n",
    "    shuffle(data_)\n",
    "    data_shuffled=''\n",
    "    for l in data_:\n",
    "        data_shuffled += l\n",
    "    # print(data_shuffled[:1000])\n",
    "    f.write(data_shuffled)\n",
    "    f.close()\n",
    "\n",
    "file_path = \"./observations/\"\n",
    "directory = os.path.dirname(file_path)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "file_path = \"./saved_models/\"\n",
    "directory = os.path.dirname(file_path)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "data = []\n",
    "j = 0\n",
    "k = 0\n",
    "shuffle_input()\n",
    "for l in open('data/input_shuffled.txt'):\n",
    "    if '<start>' in l:\n",
    "        data.append('$')\n",
    "        j += 1\n",
    "    elif '<end>' in l:\n",
    "        data.append('%')\n",
    "        k += 1\n",
    "    else:\n",
    "        for c in range(len(l)):\n",
    "            data.append(l[c])\n",
    "    #data.append('\\n')\n",
    "print(j)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use original data to create the dictionary\n",
    "def createDictionaries():\n",
    "    data_org = []\n",
    "    j = 0\n",
    "    k = 0\n",
    "    shuffle_input()\n",
    "    for l in open('data/input.txt'):\n",
    "        if '<start>' in l:\n",
    "            data_org.append('$')\n",
    "            j += 1\n",
    "        elif '<end>' in l:\n",
    "            data_org.append('%')\n",
    "            k += 1\n",
    "        else:\n",
    "            for c in range(len(l)):\n",
    "                data_org.append(l[c])\n",
    "        #data.append('\\n')\n",
    "\n",
    "\n",
    "    unique_char = defaultdict(int)\n",
    "    j_ = 0\n",
    "    k_ = 0\n",
    "    for d in data_org:\n",
    "        if d == '$':\n",
    "            j_ += 1\n",
    "        elif d == '%':\n",
    "            k_ += 1\n",
    "        unique_char[d] += 1\n",
    "    #print(len(unique_char))\n",
    "    i = 0\n",
    "    char_idx = defaultdict(int)\n",
    "    for k in unique_char:\n",
    "        char_idx[k] = i\n",
    "        i += 1\n",
    "\n",
    "    idx_char = defaultdict(str)\n",
    "    for k in char_idx:\n",
    "        idx_char[char_idx[k]]=k\n",
    "    #print(idx_char)\n",
    "    \n",
    "    with open('data/char_idx', 'wb') as handle:\n",
    "        pickle.dump(char_idx, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('data/idx_char', 'wb') as handle:\n",
    "        pickle.dump(idx_char, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# createDictionaries()\n",
    "with open('data/char_idx', 'rb') as handle:\n",
    "    char_idx = pickle.load(handle)\n",
    "\n",
    "with open('data/idx_char', 'rb') as handle:\n",
    "    idx_char = pickle.load(handle)\n",
    "\n",
    "dat = np.arange(len(char_idx))\n",
    "len(char_idx)\n",
    "print(char_idx)\n",
    "print(idx_char)\n",
    "#print(j_,k_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(char_idx,data):\n",
    "    output = []\n",
    "    for i in range(len(data)):\n",
    "        aux = np.zeros(len(char_idx))\n",
    "        aux[char_idx[data[i]]] = 1\n",
    "        output.append(aux.copy())\n",
    "    return output\n",
    "\n",
    "def softmaxT(data,T=1):\n",
    "    temp = torch.exp(data/T)\n",
    "    aux = torch.sum(temp)\n",
    "    return temp/aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_data = one_hot_encoder(char_idx,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "output_data = []\n",
    "for i in range(len(oh_data)-1):\n",
    "    input_data.append(oh_data[i].copy())\n",
    "    output_data.append(oh_data[i+1].copy())\n",
    "print(len(input_data))\n",
    "print(len(output_data))\n",
    "#print(input_data[0],output_data[0])\n",
    "#print(input_data[1],output_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n",
    "X_train = input_data[:int(split_ratio*len(input_data))]\n",
    "Y_train_aux = output_data[:int(split_ratio*len(input_data))]\n",
    "X_valid = input_data[int(split_ratio*len(input_data)):]\n",
    "Y_valid_aux = output_data[int(split_ratio*len(input_data)):]\n",
    "Y_train = []\n",
    "Y_valid = []\n",
    "for i in range(len(Y_train_aux)):\n",
    "    Y_train.append(np.argmax(Y_train_aux[i]))\n",
    "for i in range(len(Y_valid_aux)):\n",
    "    Y_valid.append(np.argmax(Y_valid_aux[i]))\n",
    "print(len(X_train),len(Y_train))\n",
    "print(len(X_valid),len(Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMMusic(torch.nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim,num_layers,batch_size=1):\n",
    "        super(LSTMMusic,self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = torch.nn.LSTM(self.input_dim,self.hidden_dim,self.num_layers)\n",
    "        self.fc = torch.nn.Linear(self.hidden_dim,self.output_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "#         return (Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_dim)),\n",
    "#                Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_dim)))\n",
    "        return (Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_dim).cuda()),\n",
    "               Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_dim).cuda()))\n",
    "    \n",
    "    def del_hidden(self):\n",
    "        del self.hidden\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def forward(self,sequence):\n",
    "        out, _ = self.lstm(sequence.view(len(sequence),self.batch_size,-1),self.hidden)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def hidden_st(self,sequence):\n",
    "        return self.lstm(sequence.view(len(sequence),self.batch_size,-1),self.hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUMusic(torch.nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim,num_layers,batch_size=1):\n",
    "        super(LSTMMusic,self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.gru = torch.nn.GRU(self.input_dim,self.hidden_dim,self.num_layers)\n",
    "        self.fc = torch.nn.Linear(self.hidden_dim,self.output_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "#         return (Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_dim)))\n",
    "        return (Variable(torch.zeros(self.num_layers,self.batch_size,self.hidden_dim).cuda()))\n",
    "    \n",
    "    def del_hidden(self):\n",
    "        del self.hidden\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def forward(self,sequence):\n",
    "        out, _ = self.gru(sequence.view(len(sequence),self.batch_size,-1),self.hidden)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def hidden_st(self,sequence):\n",
    "        return self.gru(sequence.view(len(sequence),self.batch_size,-1),self.hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = \n",
    "fin_model = torch.load('saved_models/model' + str(ts) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_seq = []\n",
    "seq_char = []\n",
    "while True:\n",
    "    test_seq.append(oh_data[i])\n",
    "    seq_char.append(data[i])\n",
    "    if data[i] == '%':\n",
    "        break\n",
    "    i += 1\n",
    "#len(test_seq)\n",
    "\n",
    "activations = []\n",
    "size = int(len(test_seq))-(len(test_seq)%100)\n",
    "\n",
    "for i in range(len(test_seq)):\n",
    "    ip = Variable(torch.from_numpy(test_seq[i]).float().cuda()).view(1,-1)\n",
    "    #print(ip.data.shape)\n",
    "    out,_ = fin_model.hidden_st(ip)\n",
    "    out = out.view(out.data.shape[2])\n",
    "    #print(out.data.shape)\n",
    "    activations.append(out.data.cpu().numpy())\n",
    "activations = np.array(activations)\n",
    "activations = activations[:size,:]\n",
    "seq = np.reshape(np.array(seq_char[:size]),(20,-1))\n",
    "print(activations.shape)\n",
    "print(seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = np.reshape(activations[:,0],(20,-1))\n",
    "neuron.shape\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(neuron)\n",
    "#plt.colorbar()\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "#plt.colorbar(fig,cax=ax)\n",
    "\n",
    "xaxis = np.arange(0,neuron.shape[1])\n",
    "yaxis = np.arange(0,neuron.shape[0])\n",
    "x,y = np.meshgrid(xaxis,yaxis)\n",
    "#print(x,y)\n",
    "for x_val, y_val in zip(x.flatten(),y.flatten()):\n",
    "    ax.text(x_val,y_val,seq[y_val,x_val],va='center',ha='center')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
